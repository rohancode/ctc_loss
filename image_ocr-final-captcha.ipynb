{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "# import cairocffi as cairo\n",
    "# import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:00<00:00, 86816.12it/s]\n",
      "100%|██████████| 833/833 [00:00<00:00, 256147.74it/s]\n",
      "100%|██████████| 113/113 [00:00<00:00, 94394.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max plate length in \"val\": 5\n",
      "Max plate length in \"train\": 5\n",
      "Max plate length in \"test\": 5\n",
      "Letters in train and val do match\n",
      "Letters in test and val do match\n",
      "Letters in test and train do match\n",
      "19 19 19\n",
      "Letters: 2 3 4 5 6 7 8 b c d e f g m n p w x y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def get_counter(dirpath, tag):\n",
    "    dirname = os.path.basename(dirpath)\n",
    "    ann_dirpath = join(dirpath, '')\n",
    "    \n",
    "    letters = ''\n",
    "    lens = []\n",
    "    for filename in tqdm(os.listdir(ann_dirpath)):\n",
    "        if not('.png' in str(filename)) | ('.jpg' in str(filename)):\n",
    "            continue\n",
    "#         print(filename)\n",
    "#         print(letters)\n",
    "#         json_filepath = join(ann_dirpath, filename)\n",
    "        \n",
    "#         ann = json.load(open(json_filepath, 'r'))\n",
    "\n",
    "#         tags = ann['tags']\n",
    "#         if tags[0]['name'] == tag:\n",
    "#             description = ann['description']\n",
    "#             lens.append(len(description))\n",
    "        lens.append(len(filename[:-4]))\n",
    "        letters += filename[:-4]\n",
    "    \n",
    "    print('Max plate length in \"%s\":' % dirname, max(Counter(lens).keys()))\n",
    "    return Counter(letters)\n",
    "c_val = get_counter('./ctc_loss_images/val', 'val')\n",
    "c_train = get_counter('./ctc_loss_images/train', 'train')\n",
    "c_test = get_counter('./ctc_loss_images/test', 'train')\n",
    "letters_train = set(c_train.keys())\n",
    "letters_val = set(c_val.keys())\n",
    "letters_test = set(c_test.keys())\n",
    "if letters_train == letters_val:\n",
    "    print('Letters in train and val do match')\n",
    "\n",
    "if letters_test == letters_val:\n",
    "    print('Letters in test and val do match')\n",
    "    \n",
    "if letters_test == letters_train:\n",
    "    print('Letters in test and train do match')\n",
    "    \n",
    "print(len(letters_train), len(letters_val), len(letters_val | letters_train | letters_test))\n",
    "letters = sorted(list(letters_train))\n",
    "print('Letters:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def is_valid_str(s):\n",
    "    for ch in s:\n",
    "        if not ch in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class TextImageGenerator:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dirpath,\n",
    "                 tag,\n",
    "                 img_w, img_h, \n",
    "                 batch_size, \n",
    "                 downsample_factor,\n",
    "                 max_text_len=5):\n",
    "        \n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        \n",
    "        img_dirpath = join(dirpath, '')\n",
    "#         ann_dirpath = join(dirpath, '')\n",
    "        self.samples = []\n",
    "        for filename in tqdm(os.listdir(img_dirpath)):\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext in ['.png', '.jpg']:\n",
    "                \n",
    "                \n",
    "                img_filepath = join(img_dirpath, filename)\n",
    "#                 json_filepath = join(ann_dirpath, name + '.png.json')\n",
    "#                 print(img_filepath)\n",
    "#                 print(json_filepath)\n",
    "#                 ann = json.load(open(json_filepath, 'r'))\n",
    "                description = filename[:-4]\n",
    "#                 tags = ann['tags']\n",
    "#                 print(tags[0]['name'])\n",
    "#                 if tags[0]['name'] == tag:\n",
    "#                     continue\n",
    "#                 if is_valid_str(description):\n",
    "#                     print('here')\n",
    "                self.samples.append([img_filepath, description])\n",
    "        \n",
    "        \n",
    "        self.n = len(self.samples)\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        \n",
    "    def build_data(self):\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "        print(self.n)\n",
    "        for i, (img_filepath, text) in tqdm(enumerate(self.samples)):\n",
    "            \n",
    "            img = cv2.imread(img_filepath)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img /= 255\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(text)\n",
    "        \n",
    "    def get_output_size(self):\n",
    "        return len(letters) + 1\n",
    "    \n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "    \n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            # width and height are backwards from typical Keras convention\n",
    "            # because width is the time dimension when it gets fed into the RNN\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
    "            else:\n",
    "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
    "            \n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)\n",
    "#             print('input_length_jth', input_length)\n",
    "            label_length = np.zeros((self.batch_size, 1))\n",
    "#             print('label_length_jth',label_length)\n",
    "            source_str = []\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                if K.image_data_format() == 'channels_first':\n",
    "                    img = np.expand_dims(img, 0)\n",
    "                else:\n",
    "                    img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                source_str.append(text)\n",
    "                label_length[i] = len(text)\n",
    "                \n",
    "            inputs = {\n",
    "                'the_input': X_data,\n",
    "                'the_labels': Y_data,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:00<00:00, 65299.14it/s]\n"
     ]
    }
   ],
   "source": [
    "tiger = TextImageGenerator('./ctc_loss_images/val', 'val', 200, 50, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger.downsample_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiger.get_output_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:00, 2406.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tiger.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generator output (data which will be fed into the neutral network):\n",
      "1) the_input (image)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB2CAYAAADRN8iWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO19eZhU1Z32e6qqt+q96W66aUTaFcFgRImKS9zBXdyVKEZn0IwxxsRRE8fImHyPUWM0mWgcd6OiaNCEmbhhFIIZAsgmIIvsW7M03VBUd1dXddX5/rj1/urUvdVA2l7xvM/DU82tW/es95z3tx6ltYaFhYWFRd+Dr6crYGFhYWHRMdgF3MLCwqKPwi7gFhYWFn0UdgG3sLCw6KOwC7iFhYVFH4VdwC0sLCz6KL7SAq6UGqOUWqGUWqWUurezKmVhYWFhsW+ojvqBK6X8AFYCOAfAJgBzAVyrtf6i86pnYWFhYdEevgoD/xaAVVrrNVrrKIA3AFzSOdWysLCwsNgXAl/htzUANhr/3wTghL39oLi4WFdVVaVdU0p9hSq0D5/Ph1gsBgDYsWMHAGD37t2e+/x+P+uGyspKAEAikZBnmM8DgLa2Nvmbn1pr+Y37fhNKKXR15GtX9WdPl9Wbyu7J8ru63ANx/uxvOXw3uSbE43H5Ld9vftfee9xVbZo/f3691rrCff2rLOCZaupplVJqAoAJANC/f38888wz7u8z/r3XgvfjvtzcXFm4n3rqKQDA//7v/3ruKygoAABccMEF+N73vgcAiEQi8gwuxPn5+QCczSA3NxcAUFhYCACIxWIIh8NpdQsGgzLIvOb3+9HW1rZf7epoX3Tkd5l+sz/PybRJdaSsjvxmf651Vln7+s3+1qejZZlojxh0pH6Z0Nv7oqvq5/P5EI1GAQBFRUUAgFAohEDAWSKbm5sBAGVlZQCAaDTa4X7vSF9kZWWt91zEV1vANwE4yPj/QABb3DdprZ8B8AwAHHnkkd2WeKW5uRklJSUAgOOPPx4AMH/+fGzZ4lQxKysLQGqxfuWVVzB37lwAwJNPPgkACAQCaGxsBABh84cddhgWLVoEwNmh+ay8vDwAQHZ2NgCHqbe0tKTVKRAIyHOCwWCnttfCwqLjSCQSacyb1/hecyE37+G1nsRXqcFcAIcrpWoBbAZwDYDrOqVWnYC8vDxZnM8991wAwPDhw/HKK68AAN555520+3Nzc/Hll18CAM466ywAwAMPPICLLroIQGoAFy1ahKFDhwIAtm/fLr+niNXU1ATAWfC5mBcXFwNwBp914kJuYWHR82hpaRHmzUU6KytL3muyc763vSUJYIcXcK11m1Lq+wA+AOAH8ILWemmn1czCwsLCYq/4SjKA1vpdAO92Ul06FQ0NDRg8eLD8DThM+M477wQA+e65554DAITDYdlVqeP+xS9+IeqSW265BQAwbNgwrFmzBgCQk5Mj95sGTcDZvcnAuXtHo9E0tYuFhUXvQGFhoTDv1tZWAEhzTHA7LgSDQY+KtCdgIzEtLCws+ih6XgvfRaiursaSJUsAON4vAFBeXi566xtuuAFAysB5zz33iIGTemoAeO+99wAAy5YtAwD88Ic/xCmnnAIgZZlubGwUjxTqyrOzs2W33rNnDwBnZ+d9FhYWvQeBQEA8yfhJDzUgJZWb0nRvQIcjMTuCI488UneXG6Hf7xcVB9UWQMpLhIsvBysrKwsPPvggAGDmzJkAkObyx2cBwL/9278BAK6++mr5LRdu+prH43FxOSIikYh4n1BMa69d1o3QuhFmgnUj7Jr6mR4npnpz165dAFKGTf5Wa53RC6UL3Qjnaa2Pd1+3KhQLCwuLPooDVoXS2toqOypVIrt27ZJr/KSLXzAYxD333AMAOPPMMwEA//Vf/yU7MBlzTk4OHn/8cQDAvHnzAAB33nknDjnkEHkO4KhVKGaRvbe1tSEUCqVds7Cw6HmYLoPbtm0DAHz55ZdYsGABAGDUqFEAgBEjRgBwGHgmKbq7YRm4hYWFRR/FAcvAs7Ozhe1Sp9W/f3/Rh1O/zc9oNIoBAwYAAC699FIAQEVFhbBtBvm0trbK8/7+978DANauXYt///d/BwCcccYZAIDS0lJ5NiUAn88nDN0G8lhY9B7E43F8+umnACDBflOnThWb1q9+9SsAjhsx4Kwb1Iv3JHq9EbM7jWlccE1fz507dwIA3nrrLQDAiy++KKoRepREIhF53o033ggAGDdunFiuqa6JxWKygfBaOBwWdYqZd4GbBJ8RDocz+o73lDEN6JhBraeNVV1Rv47+bm9zMBAIeKL9srOzhQzwt/n5+Rk9InpbX2TyqTbbyHYnEgmPz7Xf7/fMtba2Nnkm35tAICB9YcZj8NlccAsLC1FXVwcAeP311wEAzz77LNauXQsgpS7t16+fvM/jx48HABxxxBEAnHe5o0bMTLBGTAsLC4uvGQ5YFUpHwB2VO2A0GhVf0LFjxwIABg4ciClTpgAAFi5c6HkGJYw1a9bg9ttvB5AyWA4ePFgYPaO4ysrKhFWRKZSVlUn0KD8HDx4s/uQWBy7Ky8sBOFkvOfdKS0sBAIsXL0ZNTQ2AFDttbm7uFUmV9oVgMChqQ873SCQiEibbqpQSFk1pNR6PCyvmu5mdne1xE45EImm+24DzTrF/Fi9eDAB49NFHJReSGS3N+A7GiJx99tmora1Nex7Lampq6hX9bhm4hYWFRR9Fz28hvQhkwNyVtdaiN6ObYE1NjWQt+8tf/gIA+PDDD+UZzBv+0UcfYc6cOQBS6Wnz8/MlxS0NrC0tLVIedXqhUEj06/ysr6+3rodfA2zc6JyR4vf7ZT5s2rQJgDP3yLzJYnNyctIC1XorGhoaZC7z/YnFYvLOMbDOTMPMQDjaiwCk6bjZbuq7tdbyHLL9v/zlL3j22WcBQNJFx2IxDBo0CABw4oknAgDuuusuHHSQkx27osI5N6G1tVV05QTdjk3JuSdhF3ADfDn44iilZJLQH1wphRNOcA4eok/okCFD8PzzzwNIpZMFUpPy+uuvBwB873vfk/S0xx13HABgyZIlsklUV1fL7xghyslrF++vB6hSqKqq8uSiz8nJkTnFz76SFC0vL0/eKzNZFBdfvnsFBQWycFPdGIvFRHVivpt8b7ioNzc345FHHgGQIlfr1q2TOhx55JEAgKuuugqXX345AEclCjjqU3cyK5/PJ2k4zBO5AIdkkXj1JKwKxcLCwqKPwjJwA+6ENYlEQgwVZAqtra2y81IdcvXVV4uxg/lUWltbhSURv//977F0qZMy3UymRXbNRFu5ublSBhl9MBjsE6KyxVcD1QxNTU0i9ZElrlmzBjxTlmoI91msvRX5+flihCeLDQaDIkHwnQuHw8KEabxtbm4WKYTvRSQSEb/tF154AQDw5z//2cPUzz33XEkFTYm5X79+oupkuT6fT95xvmexWEzKNXOgmPf0NCwDt7CwsOijsIE8BtgXpjshd1re7/f7Pe5QeXl5sqPTADNhwgSsXr06rX6M6gJSBprbbrtNXBRZbiQSSTPcAE5KWkoI7bWpvXbZQJ6urV9Hf5fpN2Sfu3btErZNg3e/fv1EIqO0RrfDjtSvuwN5TBdAwNHfkwHzvQkEAvIumfYkGhP/+te/AgBeffVVfPbZZ2ll9OvXD9dccw0AJ5AOAEaOHOnRs7e1tcmzzeyklIRN3Tbff/6W76DP58toxLSBPBYWFhYW+wWrAzfg1rOZbJs7cW5uruzU3JXj8bjou8mW3nrrLfzud78DAPzmN7+RMuiGxACdn//851i+fDkAx0sFcPSbO3bsAJDSiRYXF/eK7GcWXQvOs82bN4sOmO6oxxxzjMzN//mf/wHgeDj1hoCSfcHv94u+m/rpXbt2CTtmjiC/3y/vEgPl/vSnP2HSpEkAUu8NAJx++ukAUvakCy+8UN5NBvQ0NDTI88z8/GS5vM/0kuGnmfOb1/gsrXWv8ADq/SPfjeBgmomuOEjm5DPzLABIe4Fo2Ny+fTt+8IMfAACGDx8OwIkA42JtprplnhWetXnLLbfgpJNOApBS67SXC8XiwMLs2bMBAJMnT5bkalw8Hn74YTHY/eMf/wDgzJXecjrM3qC19pzw7vf7xRhL9eLkyZPx0ksvAYCkctVay7t56623AgCuu+46cQs01Rp8R6hiKigoEDWTeTgDn1dfXy/3uRdwv9/frgqkNySyAqwKxcLCwqLPoluNmEOGDOmUI9Xc6CxjGpkB2bHP5xO1BUXbnJwcKc8MsOBO3q9fPwAOK2cgAkW3rVu34uWXXwaQCjQIhULCIEyjyN133w0AuOKKK+R5rDPFRK11WhY31okSAUXwUCiUFgABOAyCY8/vzCxx7AsypFAo5DFCmWW5jT3uv93shuUAqX4vLS315IUpLCyUgBa2p6mpyXPEVXtGaTNKj+CYUp3V0tIizI0GNI6dz+eTstgXra2tUneyurKyMk8Oj0AgIHOEn1VVVTJXqDbYvHkzpk+fDgD44IMPADjGOpZLJq6UEoM3j/MrLS31qPRMI5xp+CbL5TUz85/JKN1zxexPtpvtCQQCniAXv98vz+N4mvVgP61cuVKkzzfeeAOA846wXGb+u/baa3HttdcCgERLtra2pvUz67s/Dg3ddRRge7/ryNoUCASsEdPCwsLiQILVgRsgkzGZFHdDU99NdsFrzc3NnlPpfT6fJ9iipqYGP/rRjwCkmMSkSZOwefNmACmG2djYKCHBzN8wceJEYTFkk7FYTOpq5migIZWHUNTU1HgCDzKxY/MesikzrJjslO03D6Vgu1taWqQuNPgEAgGPMSg/Pz8tnwe/cxtqzf+b2elYh0zM3mSVLJf3ZzKmRaNR+d4sg/evXLkSADBt2jQAwM033yxSGsekublZxoXfxeNxj52kubkZGzZskL4CHJZKg7eZ45pju2XLFrnG+XDfffcBcCQjd12i0aj0LctIJBKi96WdZvfu3R4WC6TG1c3OW1paZJ6bemx3Lp9IJCJjyrrt3LlTcgb96U9/AgB89tlnYqxnWVdeeSW+853vAABOPvlkAM78YN8yGMjv90tdCLb16wS7gBvgy8bJpJTyLDwtLS2yuHFx5wsBpIwnQEr05SJkpgidMGECACc6jKd9mH6tfCl46s/o0aPx6KOPAnByrwBObgfWa+vWrQCcBYIbweGHHy7lcjMhTJWIWX/AebHd97e0tMiiYKbU5H3m5mcuavwtyzIXRvcmYea3MNOLuo23pujPF1sp5TkAwVShmJsTy+PYlpeXy/OYcpQLZU5ODs466ywAqVw1s2bNwtlnny3tANI3RKoqSktLRRXDnBrRaFT6jBvD/PnzJWcH65STkyNja/YFx8r0SzYXU8Dpd9PjAnDOeWS7WVZhYaGogLjp5ufnexZ1lpmTkyP+0yY5oWcI69mvXz+8//77AJxzZQFg+fLl8m6wvtXV1bjzzjsBpPIFHXroobIQZ8r/ww3B3HDYrkgkIiTj64J9qlCUUgcppT5RSi1TSi1VSt2RvF6mlJqmlPoy+Vna9dW1sLCwsCD2h4G3Afix1nq+UqoQwDyl1DQANwL4q9b6l0qpewHcC+Cerqtq14NshDt/Tk6OsESTOZIFkBnW19ejsrISQMpg2dTU5DmiraioSJjO+vXrATjs5qijjgKQEpV37NiR0TWM6pdDDz0UgHPIxLnnngsgZTyNxWLCAFl+v379xBBIJlxaWip/834yuP79+wurMjM08nmmiG2yPsBhRu4cMI2NjXLNTAdKCYWisHn8ldkGGvvIugoKCjw5KpRSGY1uvI9MPBKJSIQjx5RGRbO9lCJ27twp/vnMINnY2Ci/4Xia0hrnQjgclvayHvTpBlKnn7/++usyb9jvbW1tHikjGAxi6NChAJy8H4BzBivnoala49/Lli0DAPzxj3+UOcCoxkAgIJIes2RecMEF0t9kwqxTKBSStpH1NjY2SpumTp0qbeS7xPFsamqS1K08pmzs2LHSbqpSIpGISCt8H3JycjyG2kgkIn1r5ib6up01u08GrrWu01rPT/69B8AyADUALgHwcvK2lwFc2lWVtLCwsLDw4p/SgSulBgM4FsBsAP211nWAs8grpSrb+c0EABOAlB6wt4Jsirt8poyCwWBQdJPM2V1aWir6PTKO3NxcMbiYmcxosGRwwRNPPCGnYJPZl5SUCCMxjW9kHAwGeuihh0R/ToPPDTfcIEFAZIR79uwRvbiZ89g0KAIpl681a9bI/dSXzpkzB6tWrUq7b/jw4Rg9ejSAlASQSCTEiMr2NDY2CptiP23cuBGjRo2S/gMcnT71rez3/Pz8NCMa27W/rqPu74qKiuTZZOAlJSXCqBn9t2LFCgCOVMB5SxZ4/vnnyzMOPvhg6RO2m/cppSRLJVns0qVLRfri/aFQSJio6VJKFk02O2zYMGHbDPi56KKL0gzNgNPv1FVTF/3YY495Mhearqkcv1NPPVV0/XwG67tx40axycycOROAk8/eHa0cCAQkgyL75/bbb8exxx4LAHKYQjgc9riItrW1yTwbPHiw9IW77llZWZ7Dj7+O2O8FXClVAGAKgB9qrUP76xeptX4GwDOA4wfekUp2F7hAsm0+n08mlnn+HhdXLkbvvvuuvFD0Lhk3bhyOOeYYAEgzrFA1QONWKBSSCcgFyrSmm6fXc+JzE4jH4yLucuGZPn26LAZcXMePHy9qAy6GZkJ6blxcUBYtWiTh/3yJQ6GQJ81nWVmZbFhm//Aa+7Ourg5ffPEFgJRIv2zZMimPC8Do0aNFRcAFf9iwYWl1Zp+w3eZLnOmFdqcBzcvLk77nopCTk4MlS5YAcCIBAcgJ5UVFRbjyyivT7l+9ejWGDRsm48LncrGiQTkcDkv5jCosKyvDrFmzADjGS8BRCXGB5wJdUlIif7Pdp5xyitzHU2OysrLSvFl4jYu6uemxn9l3TU1NsjnxrM3Vq1fj6aefBgC89tprAFLzzXwGMWDAAJlnl17qCOEnn3yybMTcfLKysmTTY/+bmzPfi5ycHBx22GFp/WgasrnBBQKBtLSvbGtfSCvQmdivrUsplQVn8X5Na/128vI2pVR18vtqANvb+72FhYWFRedjn9uVcijE8wCWaa1/bXw1FcB4AL9Mfv65S2rYjSBbMo10ZFh0L3v//fclDwXFv6ysLPmN6fJFJkqmHggEhP3QZXDz5s2epPZaa2G05jmdZDgjR44E4KhSmBuDhimfzydshidvv/POO1LuGWecAcAxJFFEfe+99wAAL774IgCHzVPFQ7aktZb+oWpo1qxZwpjZ/pKSEjFK0hVv/vz5wsD5GYlEhI2Tre3YsQOLFi0CkPIVPv3009NUWoDDPtkv/G11dbWI/pQosrKyPD7uu3btkt9wbGfNmoUpU6aktZfSTigUkrJOPfVUAM44cgyoYtqxY0eaPzsAzJs3T/rio48+krqzLpQyaMw162RKbaZqgs8mS21sbJQyzERLNJByLpSXl8s1SlXmtfvvv1/KYHvdSCQSGVO9sj/5mUgkPD7ZiURCJEO2h5IFkDJkx+NxOQOUc9Dv96edPM9+chucTZfKrwv2R944GcD1ABYrpRYmr/0UzsL9plLqZgAbAFzZNVW0sLCwsMiEfS7gWutPAbSn8D6rc6vTO0C9HFkrkGLRixYtSmPeQHoUIJnJli1bJOCGjDASiQiDIPuqr6/3RB9mZWWlHeEGOMya+SIYoDNu3DhccsklAFJGtylTpgijNvOkkCGTaX700Udi7PzmN7+Z9tnc3Cx6TzM4hu2gXnPVqlWiO+Z3xcXFOOSQQwCkDG3z5s2T9pK9Dx48WJgT3ShHjBghEgyj9vx+vzB16pFNAyxdKk844QRxUzMjE90BRFlZWWIEJoOrqanxuHdyDhx66KEiZdAwV1ZWJhIUpRitteinyUTr6+uFlZPZz5kzR5go7xswYIDk/WBwT2FhobBxjuPq1avFrkJ9e3Z2tkcv7ff75XR7HirS2trqiTatr6+XOcw+a2trS7MBmfebByHwd9u2bcOTTz4JAHJc4B133CHSChlxVlaWzBs+1wzUMXX1dFUkQzf12hz3vLy8NLsL4LDy3nDQcHeiT2r83VbnjibBcsOdqMe0ftNKX15eLosRXyxzkePi0NzcLJOcYmxRUZFMNhodKS664Q7rTyQS8gI89thjAIBvf/vbcj8X3+HDh4t4/eabbwJIj8JjnSKRiHgo8JMLallZWZo/O/uG5RPRaFQWHG5q5eXlEqXIUP6lS5d6jFBnnXWW9B/vHzBggJTLZF6bN2/G3/72NwCQEPR4PC79eNVVVwFwvCHMPM6sM9UqXHwbGxtljKgG+dWvfiXJxWic5LhcdNFFMr/MqEUuMjS0VVZWShvpF33UUUfJZkrV0dq1a8VwyHqec845svk8/vjjACDJrYCUn/PUqVNls+P94XAY//d//wcAckbkjBkzRBXFfkokEmk57YH0jZAoLS2VzZttNKOLCVPNyDnK8ouKikQlwv40o2wzwVykuZhnWozNZ7jVJV9l8e7pk5o6iq+v/42FhYVFH0efZOBdhUxRXO4T6N0JdAjTgAMAn3/+Oc4880wAKYNUfX29pM+keiHTuXrmadhEbm6usGiy4lgs5klFa+aroEjf2toq9WYS/G3btomY7ZZotm7d6mEzWmthP2YaWrJiut3F43FRQ/C7YDAorJPSyMCBA0WCoFqlpqZG2JcZ7Upfavoem8mnKD1kZ2eLyorMvrq6WtztqMIAUoZcnmrz9ttv45xzzpHnsG8Bx3WPbpNsg3m+I93v5s+fL0Y3Go8LCwtFQuFnIBCQfmeKVJPlU3pauHChMH5TDfH2244TGCWGFStWpJ2sDqQb/aiaicViUgfOI6215DShAdTv94sBl33C7+bPny9jy/lmuvPxvpkzZ8ohJhy7r1uOku6CZeAWFhYWfRSWgRswXfYI/k0mV1lZ6clRkZ+f79EPx+NxYTxkbvfff78Y/UyQTZKlhMPhtGOdgHSmzkCi2bNn41vf+lba942NjWK4ohGspKRE2kZW9d3vflf08Exlyv8PHDhQ2kPdJJ/lhpvtl5aWSoAKGVkkEpHzC9kXgwYNEp0xGW5DQ4P0AY1006dPF5bLaNNPPvlE6sX+9Pv9Yoj8xje+AcAZK3eq06qqKjm6jmM6ZswY0fOyHSeccAIAh+lSR89gqNzcXM/BE21tbSJJ0Pi2YsWKtAMfAODoo48WfTiljUmTJombKvXPu3fvljaagVE0FHLuFRYWyhxgXpzTTz9dDL90c6Rbpvlbs65mlCkNkIycpB1h+fLlciAJ857s2bPHEzyzbds2fPLJJwCA0047DUDqWEGLzoVdwDPAtNa7U65WVVWJ2MmXs6mpSb7ngjZjxgwRN7nImGlbzTzjfEHpDxyNRmWRMevi9sF95513xKhF8X3FihViWDND6Y8++mgAKa+J5uZmEdefe+45AKlFrqGhQVQ89C+fPn26LDKmj6/bZ5jGTLN80y+ZHh2lpaVSJ26I69atk0WQKpTKykrPKTkzZswQNQBVSIMHDxY1Dv30Q6GQGJ+5+JtRoVTJrFu3TjY9bhannHIKAGecON7cxMyDd2ks3L17N2bMmAEgpR7bunWrx4d9xowZ4mnz7rvvAnCMotyUiWAwmOb9AThqEBqrb775ZgDAeeedJ2PP+7KysmQOcMz27NnjUYuZice4wF599dWStIt15gZ76qmnypgy3H327Nmeg4kTiYSQFxqy7QLeNbAqFAsLC4s+CsvADbgPdGhraxMWRPZSXV0tagBTbeL22c3LyxPmbeYz4W8pqsdiMWHZNDhFo1ExAJpuSOYZnIDjy80zEunT/eWXX8qzidraWmF97nwmADw5SYqLi0VtYJ4NyfaSXQHpEXlumGdJfv755wBS+T/a2tpETUIGOWjQIGHAdPsrLS0VFsnfFhcXC3Nknevq6sRASrVBdna2JzmVz+eT72nENNPJUgp5/vnnATgMn/lt6Ie+atWqtKRggKPKoPTAeRSLxdJSEwMO66XxltLBsGHDRCqgFLZhwwbJRWKCKrBrrrlG2sM6cBwrKytFumEE6Pr169NSAwPOPOO8psRRW1ubdsYkkJKq/H6/xCDQYDx//nzPwRzxeFxUUhwTi66BZeAWFhYWfRSWgRswdbYEGTiv1dTUCHMkqwNSkYhmlkHqZ6kzfvDBB0UX/NRTT8lzaUwjq2lsbBSWZGb7I8OhHruurk7Ko656w4YNHgPbnj17xChHCWD79u3CXqljNiPvyCbZhuOOO070meZhD2RaZtQq2T5/e9JJJ4lrGpnz7NmzPUFACxYs8Jy3GQwGPSl9fT6fJwDFvIfBM/zcF8rKyqRNbDdtEECKiZIdV1ZWigTDsQuHwzJ/yKYLCwtFQmH/33bbbSJpUbeenZ0tRkFKG6FQyJNxMRwOp+m5WV+OARn45s2bhYGzfqyPeZ/W2pNNsqioSJ5NwytZtJlR0Mzf4j62zswDZNpELDofdgHPAPdJOiaqqqpkATdTlXKRNq/xb55ledBBB4l13ryPLwMX5ry8PHnZ3KfrACnR+7jjjpNIN75Yu3btkhfKzEvNkHOWYS6CLIuLl9Za1Brsg/79+3uiRuPxuHg3mOIz28MFKBgMikcDy/rZz34maiIaHWfOnOk52aiiosKjnvrggw9kgeWisW3bNmkbvUVisZg8j3Wpq6uTxZoeHw0NDbKY0ihMVcHo0aPFd56RmywPgPh0L1y4UDxEuIBXV1dLGezr6upqGRczYpSbN8fg448/9mxcJSUl8rz//M//BOCkKeAmfvHFF0ufccPgZgqk5hLVJoFAQOYtx9bMd8/ncmzz8/NlPpgnQBHmAc4kETSmWnQNrArFwsLCoo/CMnADmdQW7pPOS0pKhJ2aSX/IlswEO2R9ZnrMTNGeNHJSDQOkjHiZjEAUSy+99FJxBaTr2tq1a4U5UaSvqakR5ktmlEgkpH6M5CMbKykpSXMpBBxjItkc2WIwGBRXODMvBVkXVSi1tbXSP2TbQ4cOFTXEhRdeCMDJ7cJrZH3RaFSMjmTiWVlZktiLbnWTJ0/2uMmtW7dO+pFud1u3bpXkS3viUKsAABqqSURBVOyLiooKnH/++QCAK664QtrGssjAqXrw+/0i+fAZgwYNkihbsv5ly5bJHGGekOuvv15YPus2cuRImQOULFauXCksl+MZDoflLEzOo0QigQsuuCDteXPmzBGXSs6p7OxsGSPzk2NkJo5i33MOcEwSiYSohMxzTN3nk5pupm4pwqJzYRm4hYWFRR9FtzPw7srW1dzcLMY5kxWbp8sD6aeu8zuyoWAwKOyZxr9wOIxXX31VfuNuB9mLUkqeR93oueeeK/pR/taM6qNxa/369aJH5v1mUBENltu3bxeGQ1Zu5vwwQf2wef6lecI36wI4Egj7h6w7Ho97su0NGTIkYwJ9d9TmJ598guOPPx5AitnGYjEpn1LGwQcfLK6KbE9xcbHo75n/wzTM0SXvpZdekn4hO3zggQfEkEkJpbi4WPTXHIMdO3aIIZASF/u/oKDAk+VQKSV9RqZ73333CfOm/nz16tWe+b1+/XrRY7MvXn311TR7AeEey30dWGDOD7J3M12sO2dKIpFIk8gAx4ZCe4A7SMtMe2y63LptKCwPQFpaYrfRPJFIyDNNe43bQP1V0VXZS/eVwfCfKasjmQ+BA1iFUlhYKB3BiRuLxdJeQiA9PSUnFtPFFhcXy+SkWuCee+4Rw5W54LkNn1prWcjMg4G5MJmJh8zcziyXi9a0adPkfk5svnSLFi2SfOCMjDNfcNavsrLSkzvZ7INMoBjM/snKypKFkxGmS5cuTWsH28BFnwslAFF5PPjggwCAF154Addffz2AlEGsrq5O+sA8i5RRigyRLy4uFhUGz7AcM2YMPvjgA6kXADz99NOSMIoLyVNPPSXP42J57LHH4qc//SmAVKSomYiLmwrnR1tbm/TzmDFjADibCucFDbumIZu/bWlp8fhNt7a2yn2mDz83BG5wmdIZFBQUiI89fcPPO+882diprjFVcZkWSM6f8vLytMRWQGphLioq8mwCpv+7CbcKzu/3yzWz/EwpZrs6BeuBBKtCsbCwsOijOGAZuM/nS0s0BDi7fXvilJmCk+qStrY2Ya733nsvAMddzJ1gymQRZhQnyyWj//TTTz0SQGtrq7Btll9cXLxfuSOWLl0q7Ie5PExQzD388MPT8lSw/ExukgRFYN4fDocl7welEfNMQz5/5MiR4ipJJh4Oh4UBs0+mTp2Kf/3Xf017TktLizBV9lNbW5u0g8bExYsXY9y4cQCA22+/HYBzKARzePC0nC+++AI///nPAQCjRo0C4Bh0+WxGYC5YsEBYMyUAnioUjUZlDrBPIpGItIPjeOihh4pBlYblmTNnynOoCgNS6gJTfeA+QxLwHqRQUFAgRkQz8RndJikBjBo1SsaNhz3ceuutctq8OS7uU3rC4bDnRB4ikUhI/7ANJSUl0o9mu9g/nCs+n0+M6izL5/N5UhQrpdJcbC32DsvALSwsLPooDlgGbjJg7vzZ2dmek+czpdakESeRSGDixIkAIKwSgEefXFpampZPg2BZ1Cl+/vnnHsaTSCTE/cvMo0JXPT7D1AuSkTY0NIg+2s1wgZSEcNhhh6UZjvi89hi41trDfsLhsBzRZp5qTp3oWWc5x6OOHTtWXOaosw0GgyIpfPe735U2UFfNpP/FxcWeY+p8Pp/o8tkHO3bskEhDsu5nn31WdOpk4KWlpdLff//736VvOc7Usz/wwAO4+uqrAaTmBeu7e/duMWjyWktLi/yWfRiNRmWesT0XXHABRo8eDQB4+OGHATjS2B133AHAOcoNcA6YYM4SM0ul2+bR0tIi/XLLLbcAcBjwTTfdJN8DjjGYtpYXXngBAPDII48IAzddWTmXqSufM2eOpKdlWWb2TUohbH97BzVwflP3HolE0o5yY99xfNwSjVm+Rfs4YBdwpZQnOVUikfCoVUzQZ5beDJMnT5bTVcxncGJNmDABgOOzS1E1k4GGZe3YscNjoCkqKhJjFREIBESNQwPn1q1b5aUww/uZEpWialNTk2fRN6P/zP5xvyCsbyKRkMWXm8+mTZvEGGt66zDPN/2sX3zxRTzxxBMAgP/4j/8A4CwYbg+fBx54QLx57r//fgDOYkDDJ33tTU8J9uOIESMkDP+Xv/wlAGchYvIwqnN2794tIj/LD4VCsuhwkZs7d64kc2K/c7EpLS0VIyb70OfzecairKzMEz4+ceJEMYLPnTsXgKPymTRpEoCUQXfUqFHS37NmzfKUwWcMHTpUxpm+8/F43JM7nvMXSOXjnjZtmqhz6GuulJLFnKmOv/jiCzEWsw9Mzy3OKRq0c3NzPSlzTd9wM1LWHcHMdgLp741duPcfVoViYWFh0UdxwDJwIN2lD0gXHckuzNSZ/J5pRl9++eU0gw/gMMjLLrsMQEodMGnSJDEi0pCUqR6JRELKY1lVVVUiKRDRaFR+c8wxxwBw1CVkoqYrINUVppsYGShPUgkGgx53LZPhEabEwP6h6mHevHlyzawvIxipBho6dKikXyXjW7dunYwBfZufeeYZMe4yT8qYMWOEMZuHGJD5sv0DBgyQNlIqmDhxoqh46Fq4fPlyz5mjeXl5ogKi8e+yyy4TwyPrRDbZv39/j/+yGdVIRlxWViZzhe1OJBLSVz/4wQ8AOFIeJTfOqdLSUvmePuQbN24U90AaM+fOnevx3afqA0i5Y0YiEWHtjzzyCABHteV29zPnPI2stbW18myWRVfAyspK6ReWVVJS4pEqTdUcv1u7dq2kCjbnIpm3adh0R3ZatA/LwC0sLCz6KPabgSul/AA+A7BZa32hUqoWwBsAygDMB3C91rr9MLFuRjwe9+jX4vG4sDmySe72DQ0NktKTxh4gxZJoyDnppJPEgESGMHz4cDlswMw+5z4MorW11WM4rKysFDZHdh6NRuXZJ554IgDH1Y11YXsCgYDojE3jKNkujWmmftEsvz0Gbp5ATxY4Y8YM0YczYnTYsGHiAkkD2mWXXSbuhgwsefzxxz0G4iVLlsgZjgxWqq6uloMpzNwc1M+yvg0NDdJGBuXMmTNHJA5KRu+++66k/GVErRlNSGNddXW16IXJyslgN2zYIHU2IyNZFu/PyckRhss+jsViMrY0hDY3N4v0wOe2tLRIpkMGKP3617/GvHnzAKRnFOR5lTyoor6+HpdffjmA1AEjoVBIJDIaG81j29yGdCBl+L344os9um/TrdAdmFRVVeWZR2Yfc5zWrFkjc5l2EHOuco6akqH7rE0LL/4ZBn4HgGXG/x8G8LjW+nAAjQBu7syKWVhYWFjsHfu1xSmlBgK4AMD/A/Aj5WzDZwK4LnnLywAmAvh9F9Sxw3B7Y5jucWRG1HmuWrVKstTxnpKSEmE1dFt76KGH5LdkKkOGDJFcI2ZCfjMYhTDZCeDoEs28KICjw+RvGRxSWVnp0a/7/X5Pgv94PC5Mmcytra1NnmeybEofZIymzYCMlTre5uZmYcVk4JdccolINMzfbbZjxIgRAICbbrpJcqKbGQOpWyU7XblypYSyc8yKi4s9fRYIBITFUd+cnZ2NDz/8EEBKasjLyxPPIobGa62FPfOzoKBA7mO5bLd5wIGZF4Z14vwoLy/3BMCUlpbKWJgslf1uSl6m2yTg2DT4N5n6li1bhPEz9L22ttaTM76iokL6me2oqqpKS/1AsB8pQUWjUSmP9SOLNw9GJjvONO6RSES+Nz2w3HmITA8a0/Oks3OhHMjYXxnlCQB3AyhM/r8fgF1aa86ETQBq9udBezNM7C0ycG/PyPRMcyJyMaqoqJCJyglG0fGRRx7xuBbu2bNH3OQY0ZeVlZX20hJM1sTnhUIhmezmSTcEy49EIrKQmHlFOIn5jKOOOkqeTWRlZaXleeH97v444ogjPAbQnJwcz8vDxUYpJWoQur81NTWJ6E8XsurqalnczKhCLqpcNI866ijZiJhUyufzSXvo815ZWSlqA5796Pf7ZeNgf+/Zs0fawQWtvLxcxpvqiC+++ELUYeYBGVysucHk5eWlHUbA+rFf3QuKUirtLEzAmW9uQ7GZStX0fTafQ7DcZcscITccDkv9qGIqKyvDH//4RwAp99Kf/exnMge4GPv9flHn0KXw4IMPxnnnnQcgdVL88uXLPQv4559/Ln3rVqXE43ExAHMzO+KII9LmMpB+ehTbuHr1armP35WUlMi7yXmeSCSk3EzuhF1l2NxXYqrOLLczy9rniqmUuhDAdq31PPNyhlszOm8qpSYopT5TSn1mHgJsYWFhYfHVsD8M/GQAFyulzgeQC6AIDiMvUUoFkix8IIAtmX6stX4GwDMAMGTIkG7z0A8Gg2J0ojFvy5YtEqhBV0FGyEUiEY/L4JFHHilHV5kRd3ShovolNzdXnkv2uWLFCmFG/O6UU04Rpk4WWFZWJkY6MrZIJCJsjmV9+9vflmT+ZKRmdjpTNUKmTHc+IMVwTFULf0NmxA12/fr1YvwzxXPmH2GGP1MCMQ2wLIv9vnz5clGh3HjjjQCcAxCmT5+e1p4NGzZIRCJVVkVFRdI/ZIlmalv2QWtrq7Sbbnfnn3++GJVff/11AI7xjS6PDKDSWstcyZTroztPVue8qKqqEumCDLyhoUGMh+wTn88n7TbVg5QmOX9OOukkz/F7GzZskHFjENSQIUPkt24mnp+f78lnUltb65FczYyYHKclS5bIdTNToZm6mb8156jF3rFPBq61/onWeqDWejCAawB8rLUeB+ATAFckbxsP4M9dVksLCwsLCw++ip/OPQDeUEr9AsACAM93TpU6B/F4XJgdGUR5ebmEMTNHhMkeyObI/h5++GFh3qb+lUyCrCEnJ0d0kgxxPuGEEzwH5ALpp60DDhtyB/fk5eUJm2Ldv/GNb4gemUFD5snybEcikRCGQ111a2ur5yBd09BEFkTd5Pr16/Hxxx8DSBlRc3NzccYZZ6T1RSKREEZI3WhRUZGEklM/PHLkSKkzA4PGjh0r0s3vfvc7AMC4ceNEBz5+/HgATkY/MkYzpw3bQampuLhYJAqGo0+ZMgVvv/02TDQ1NUmfkuFWV1eLzpj9yb7Yvn27Jw1Bd+Duu+8Wgy5tBMuXL5dxpnRz11134Te/+Q2AdJ0xJQmOVUVFhcfGtGfPHrEbUOIqKyuT9rrD4ZVS0k/Ud1dVVUkZmfIB8V3ZtGmTzDNKD7t375b3gHXbuXOn1MkG8uwb/9QCrrWeDmB68u81AL7V+VXqHBQVFckk5sTavn27eJq4k/TH43GZiL/97W8BOIsCFyaK0WYSKD5/165d8hwueNFoVKz3XDCam5s9nil+v18WCy5AeXl58vKYp+XQIMeNadmyZXLiDHOi1NXVyYtipql1+/QC6Sk8zXqWlJTguuscByOeERmLxUQVZIrILIvtCYVCYpSlisnv94vqiIbNhx56SPrb9FdnThVG7c2cOVM2VC64W7Zs8URnmmqn73znOwCcBGQzZswAkFqgamtrPbk+GhsbRT3Da5k8eLoDNFy2trZKcq4FCxYAcJJj8QSgu+++G4BjNOdcMVVimVLBmudoAs64cwGlF1VZWZkQGdOwCDh9zDHgJt3c3CxeSVzcTa8hzq1du3aJ5wzTApsRx/zMysryJL2yaB82EtPCwsKij+KADXXaunWrGKnITMaOHSu7O0EGV15ejv/+7/9O+66goEBYC5n44MGDJf8GRb2ioiJ5rqkaISMhW8nPzxcWa16jioBlNTc3p7mxAQ4zJIsm2x82bJgYppjRb9WqVaKuIIMy28y+yM3N9agLqPI4+uijJQcLWfLOnTvTToon6MtNxurz+STiz4ygpDsbpZJIJCLPZoSeaSxkFGdjY6P4idOlcejQoWJ0ZHuqqqqEKZKlTps2Tf5mW7du3Sr1N7Mcuv2bTaO1O1dNV8I0yo4dOxZAKmJ09erVuOGGGwCkJJ9rr71W5o8ZcWzm/QHSD1QwWa87fW9ra6s8j/PBjKOg2x/HbuDAgSKxMhp55cqVYkimH7qp4mKZprsh6xQMBvd67qdFOiwDt7CwsOijOGAZeElJibiQPfTQQwAyMxOy0+eee06MjswvUl9fL9/THWvFihVyH3V6puGOTKa4uFiMiCa7IXM0IyMzBY+Y+SII6mnJwPPz84V1kSUOGjRIGCuj5MxDeDNlfeMnWXRFRUXaie2Aw8LcASMFBQXCzliWeWivyeTc1/r37y+2CdZp0KBBwkD5edBBB0mfUacfCoWE3bPv6urqRD/LfmptbRXJiZLPaaedJodPMANhIpEQ9s82kn2aAU/dAc6BAQMGiK2DBydv3LjRM6e2bNmS8VAFPseMRnYbBc283ebcc2fqNBkxy+I9DQ0NYlOg3SIajcpcYplNTU3C2ll3MwLVPMjCbZ+yaB8H7AIej8flpaXYuXjx4jSVBOCkjAWcBZeh6lyMzKRS3AwOP/xwMYiZJ+lwAeX9iURCFnVeCwQCHpE1HA7LAkGVjHlWIZFIJGRRMcOe3WdX5uXlSXlU4ZiLkHkYhPvlMf1/WT5VQmVlZbKYc3E1E4ZRZDbD0nlaUH5+ftphEbxG8dk0hPLlZd9u375dFjIu0CUlJbLJ0vgGpFKiMpSe9QXSfZ+pzqF4X1JSIn3LPmC7mpubu1WFwvm5c+dOaS83IfOUHi6qVVVVshGyj/1+v/zNsY3H42meSrzPbZCPx+MyD6liYp0CgYDnxCIgpYKjesyMXjXTEPA3HItgMOhJWOXz+WQ+WOwbVoViYWFh0UdxQDNwMkwa+t58803cddddAIDvf//7AFKGNvM8RlPsdIvg27Ztk9+QebS1tQnjMY1fBBlNIBAQox/ZSlNTk8eQ09bW5nH58vl88reZwIoMmaw4FosJAzalApOd8XlkOm6GGQ6HxU2P7c/JyZH6mS58VC2Z/sGs+6BBgwA4oj+jQsmw6+vrPX22a9eutMRJbD9VQuzTlpYWYW5/+MMfADiSEdULZNjvv/++tJEM88c//rGkZOX8aGpqkudl6qfuBOvp9/tFWiJjLSsrk35hfXfu3ClzgPPDdBk0E2xR6jTVK+7UraFQSPrMnR7XTCzGskzJjO8IkJqPLNNUFVK9EggEpL3mEX6cX5mOPbRIh2XgFhYWFn0UqjuDFIYMGaKfe+65dr/vzGyEnZXxq6fK6sz6ZUJ7WfG6oqx9tcvUxbtZvnlIMyWLrVu3isvaW2+9BcBh3YwUZZ6bVatWCXsnm/vJT34ibnmUEExpjSzRDLjKdLBAR6ME99Xv3Tlv9/W7jtSvM8va128yIdMaciD0hc/nm6e1Pt59/YBVoVj0HZj5od35zZVSaaoOwFG/vPbaawAgJ/g8++yzIDmgQbKiokLULv/yL/8CwIl0pIGUm4RpSHYvAN2tQrGw+GdgZ6eFhYVFH0W3qlCUUjsANAHwZr3pfShH769nX6gjYOvZ2bD17Fz0hXoerLWucF/s1gUcAJRSn2XS5fQ29IV69oU6AraenQ1bz85FX6lnJlgVioWFhUUfhV3ALSwsLPooemIBf6YHyuwI+kI9+0IdAVvPzoatZ+eir9TTg27XgVtYWFhYdA6sCsXCwsKij6LbFnCl1Bil1Aql1Cql1L3dVe6+oJQ6SCn1iVJqmVJqqVLqjuT1iUqpzUqphcl/5/eCuq5TSi1O1uez5LUypdQ0pdSXyc/SHq7jkUafLVRKhZRSP+wN/amUekEptV0ptcS4lrH/lIPfJufr50qpET1Yx0eVUsuT9XhHKVWSvD5YKdVi9OnT3VHHvdSz3TFWSv0k2ZcrlFKje7iek406rlNKLUxe77H+7DCYVrQr/wHwA1gN4BAA2QAWARjaHWXvR92qAYxI/l0IYCWAoQAmArirp+vnqus6AOWua48AuDf5970AHu7perrGfSuAg3tDfwI4DcAIAEv21X8AzgfwHgAF4EQAs3uwjucCCCT/ftio42Dzvl7QlxnHOPk+LQKQA6A2uRb4e6qeru8fA/Cznu7Pjv7rLgb+LQCrtNZrtNZRAG8AuKSbyt4rtNZ1Wuv5yb/3AFgGoKZna/VP4RIALyf/fhnApT1YFzfOArBaa72+pysCAFrrvwFocF1ur/8uAfAH7eAfAEqUUtU9UUet9Ydaa6bm+weAgV1dj32hnb5sD5cAeENr3aq1XgtgFbrpQPS91VM5SUeuAvB6d9SlK9BdC3gNgI3G/zehFy6SSqnBAI4FMDt56ftJsfWFnlZNJKEBfKiUmqeUmpC81l9rXQc4mxGAyh6rnRfXIP3l6G39CbTff711zt4ERzIgapVSC5RSM5RSp/ZUpQxkGuPe2penAtimtf7SuNbb+nOv6K4FPFNKrl7l/qKUKgAwBcAPtdYhAL8HcCiAbwKogyNq9TRO1lqPAHAegNuUUqf1dIXag1IqG8DFAN5KXuqN/bk39Lo5q5S6D0AbgNeSl+oADNJaHwvgRwAmKaWKeqp+aH+Me11fJnEt0glGb+vPfaK7FvBNAA4y/j8QwJZuKnufUEplwVm8X9Navw0AWuttWuu41joB4Fl0k8i3N2ittyQ/twN4B06dtlG0T35u77kapuE8APO11tuA3tmfSbTXf71qziqlxgO4EMA4nVTYJlUSO5N/z4OjWz6ip+q4lzHuVX0JAEqpAIDLAEzmtd7Wn/uD7lrA5wI4XClVm2Rm1wCY2k1l7xVJPdjzAJZprX9tXDf1nWMBLHH/tjuhlMpXShXybziGrSVw+nF88rbxAP7cMzX0II3d9Lb+NNBe/00FcEPSG+VEALupauluKKXGALgHwMVa62bjeoVSyp/8+xAAhwNY0xN1TNahvTGeCuAapVSOUqoWTj3ndHf9XDgbwHKt9SZe6G39uV/oLmspHKv+Sji72n09bb016nUKHHHucwALk//OB/AKgMXJ61MBVPdwPQ+BY8lfBGAp+xBAPwB/BfBl8rOsF/RpEMBOAMXGtR7vTzgbSh2AGBxWeHN7/QdH7H8yOV8XAzi+B+u4Co4OmfPz6eS9lyfnwiIA8wFc1MN92e4YA7gv2ZcrAJzXk/VMXn8JwK2ue3usPzv6z0ZiWlhYWPRR2EhMCwsLiz4Ku4BbWFhY9FHYBdzCwsKij8Iu4BYWFhZ9FHYBt7CwsOijsAu4hYWFRR+FXcAtLCws+ijsAm5hYWHRR/H/AUDW2CSTKD5gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) the_labels (plate number): wxy4n is encoded as [16, 17, 18, 2, 14]\n",
      "3) input_length (width of image that is fed to the loss function): 48 == 200 / 4 - 2\n",
      "4) label_length (length of plate number): 5\n"
     ]
    }
   ],
   "source": [
    "for inp, out in tiger.next_batch():\n",
    "    print('Text generator output (data which will be fed into the neutral network):')\n",
    "    print('1) the_input (image)')\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        img = inp['the_input'][0, 0, :, :]\n",
    "    else:\n",
    "        img = inp['the_input'][0, :, :, 0]\n",
    "    \n",
    "    plt.imshow(img.T, cmap='gray')\n",
    "    plt.show()\n",
    "    print('2) the_labels (plate number): %s is encoded as %s' % \n",
    "          (labels_to_text(inp['the_labels'][0]), list(map(int, inp['the_labels'][0]))))\n",
    "    print('3) input_length (width of image that is fed to the loss function): %d == %d / 4 - 2' % \n",
    "          (inp['input_length'][0], tiger.img_w))\n",
    "    print('4) label_length (length of plate number): %d' % inp['label_length'][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and train functions, network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def train(img_w, load=False):\n",
    "    # Input Parameters\n",
    "    img_h = 50\n",
    "\n",
    "    # Network parameters\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "        \n",
    "    batch_size = 4\n",
    "    downsample_factor = pool_size ** 2\n",
    "    tiger_train = TextImageGenerator('./ctc_loss_images/train', 'train', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_train.build_data()\n",
    "    tiger_val = TextImageGenerator('./ctc_loss_images/val', 'val', img_w, img_h, batch_size, downsample_factor)\n",
    "    tiger_val.build_data()\n",
    "\n",
    "    act = 'relu'\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "    inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                   activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "    # cuts down input size going into RNN:\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "    # Two layers of bidirecitonal GRUs\n",
    "    # GRU seems to work as well, if not better than LSTM:\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "    gru1_merged = add([gru_1, gru_1b])\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(tiger_train.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "    Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[tiger_train.max_text_len], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "#     if load:\n",
    "#         model = load_model('./tmp_model.h5', compile=False)\n",
    "#     else:\n",
    "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    \n",
    "    if not load:\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "        model.fit_generator(generator=tiger_train.next_batch(), \n",
    "                            steps_per_epoch=tiger_train.n,\n",
    "                            epochs=2, \n",
    "                            validation_data=tiger_val.next_batch(), \n",
    "                            validation_steps=tiger_val.n)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model description and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next block will take about 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 833/833 [00:00<00:00, 113069.75it/s]\n",
      "184it [00:00, 1836.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "832it [00:00, 2158.86it/s]\n",
      "100%|██████████| 112/112 [00:00<00:00, 80328.67it/s]\n",
      "49it [00:00, 486.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:00, 582.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 200, 50, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 200, 50, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 100, 25, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 100, 25, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 50, 12, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 192)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 50, 32)       6176        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 50, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 50, 512)      1574400     add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 50, 512)      1574400     add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 50, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 50, 20)       20500       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 50, 20)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,852,196\n",
      "Trainable params: 4,852,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "832/832 [==============================] - 1011s 1s/step - loss: 15.2545 - val_loss: 18.2427\n",
      "Epoch 2/2\n",
      "832/832 [==============================] - 1040s 1s/step - loss: 10.6618 - val_loss: 16.9807\n"
     ]
    }
   ],
   "source": [
    "model = train(200, load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to decode neural network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = ''\n",
    "        for c in out_best:\n",
    "            if c < len(letters):\n",
    "                outstr += letters[c]\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:00<00:00, 66604.32it/s]\n",
      "112it [00:00, 1629.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "batch 1 - pred_texts ['npg', 'n5yy5', 'npf', 'n55']\n",
      "batch 1 - true_texts ['nnp4e', 'nny5e', 'npxb7', 'nw5b2'] \n",
      "\n",
      "batch 2 - pred_texts ['nbcd', 'mggwm', 'mwm', 'nxcxx']\n",
      "batch 2 - true_texts ['nwfde', 'nwg2m', 'nwncn', 'nxc83'] \n",
      "\n",
      "batch 3 - pred_texts ['mxm', 'nfcd', 'mnw44', 'nx']\n",
      "batch 3 - true_texts ['nxcmn', 'nxf2c', 'nxn4f', 'nxx25'] \n",
      "\n",
      "batch 4 - pred_texts ['mxxx', 'n3ww', 'n33', 'npx']\n",
      "batch 4 - true_texts ['nxxf8', 'ny3dw', 'ny3nn', 'ny5dp'] \n",
      "\n",
      "batch 5 - pred_texts ['n5np', 'n5xx', 'ng', '7ggy7']\n",
      "batch 5 - true_texts ['ny8np', 'nybcx', 'p24gn', 'p2dw7'] \n",
      "\n",
      "batch 6 - pred_texts ['npg', 'n2xx', 'nppy2', 'mgg4']\n",
      "batch 6 - true_texts ['p2m6n', 'p2x7x', 'p2ym2', 'p4nm4'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tiger_test = TextImageGenerator('./ctc_loss_images/test', 'test', 200, 50, 4, 4)\n",
    "tiger_test.build_data()\n",
    "\n",
    "net_inp = model.get_layer(name='the_input').input\n",
    "net_out = model.get_layer(name='softmax').output\n",
    "p = 0\n",
    "for inp_value, _ in tiger_test.next_batch():\n",
    "    p = p + 1\n",
    "    bs = inp_value['the_input'].shape[0]\n",
    "    X_data = inp_value['the_input']\n",
    "    net_out_value = sess.run(net_out, feed_dict={net_inp:X_data})\n",
    "    pred_texts = decode_batch(net_out_value)\n",
    "    labels = inp_value['the_labels']\n",
    "    texts = []\n",
    "    for label in labels:\n",
    "        text = ''.join(list(map(lambda x: letters[int(x)], label)))\n",
    "        texts.append(text)\n",
    "    print('batch',p,'- pred_texts', pred_texts)\n",
    "    print('batch',p,'- true_texts', texts,'\\n')\n",
    "    if p>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
